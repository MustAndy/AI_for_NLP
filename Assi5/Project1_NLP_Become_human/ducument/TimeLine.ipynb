{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为前段时间的毕设，所以很晚才开始制作这个project，因为我没法及时提交工作，所以就选择了自己一个人慢慢做；用此notebook来记录一下自己的开发过程，以便我做完之后进行反思复盘。Orz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' no bug no life =, = '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" no bug no life =, = \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "在自己完成了assi1-4的情况之下，开始思考这个项目。先去补了前面的两个课程，发现自己在word2Vec部分几乎没有能够理解好...今天对这一块知识进行补充，并且根据之前课程代码进行学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前基本决定是先完成后台算法的核心思路，然后再进行前端的对接，前端我flask没用过，但是用过django；这次想尝试补充一点前端的知识，因为我真的前端0经验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.12\n",
    "母亲节快乐=，=~\n",
    "今天在理解了词向量之后，开始进行核心功能的构造；\n",
    "目前合并了wiki和news的两个语料库作为词向量模型的训练数据。\n",
    "\n",
    "    Q问题：每次启动程序难道都要加载吗=，=？小电脑跑不过来了，这个问题后期思考；\n",
    "        A：发现可以保存模型....\n",
    "今天布置pyltp以及相关概念的复习。并且通过代码来更好的学习这些概念。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今天继续听第五课第六课录播课，然后补全概念；之后配置pycharm、sql等开发环境，并搭建项目模块框架。以前是写pure c的.. 然后之前做python都是jupyter+vscode+cmd+anaconda的硬核手段...\n",
    "\n",
    "犯错误：git clean -d -fx, 把所有忽略的文件删除了。\n",
    "\n",
    "重新使用了wiki的全语料重新训练了word2vec的模型，现在模型性能不错。\n",
    "因为犯错，重新整理了一个dataSource的文件夹专门存放各种模型和数据集，不和代码的git放在一起了Orz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始着手项目，先用jupyter一步步制作，然后移植到pycharm里成为一个class结构；\n",
    "\n",
    "今天是搜索出所有带‘说’意思的词，然后继续熟悉pycharm。\n",
    "\n",
    "使用lru_cache对model函数进行了结果储存，深度1000提速到120s左右，在最后可以使用dp再次优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今天完成了对搜索算法的优化，然后因为身体略差..今天不推展进度。今天收拾一下毕设的最终文件交了去评分。已解决。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高烧...身体虚弱，躺着出汗就完事了...晚上好一点了，起来把第六次课补完了，对整个算法模块有了初步的认识和想法，明天开始进行落实验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今天加入了python的翻译大队，去贡献一点微薄的力量。\n",
    "\n",
    "今天进行依赖分析，完成对句子的分割与识别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "继续前一项工作，然洗完今天能开始tif关键词的头\n",
    "今天使用pyltp的模型完成了一定程度的语段言论提取，不知道在多个数据集上性能如何，但是目前可以准确的提取出“xxx说xxx”类似这样的句型。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
