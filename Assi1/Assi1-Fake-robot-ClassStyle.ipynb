{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编写一个程序, ```get_response(saying, response_rules)```输入是一个字符串 + 我们定义的 rules，例如上边我们所写的 pattern， 输出是一个回答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Question1_simple():\n",
    "                 \n",
    "    def is_variable(self,pat):\n",
    "        return pat.startswith('?') and all(s.isalpha() for s in pat[1:])\n",
    "\n",
    "    def pat_match(self,pattern, saying):\n",
    "        if not pattern or not saying: return []\n",
    "\n",
    "        if self.is_variable(pattern[0]):\n",
    "            return [(pattern[0], saying[0])] + self.pat_match(pattern[1:], saying[1:])\n",
    "        else:\n",
    "            if pattern[0] != saying[0]:\n",
    "                return []\n",
    "            else:\n",
    "                return self.pat_match(pattern[1:], saying[1:])\n",
    "\n",
    "    def pat_to_dict(self,patterns):\n",
    "        return {k: v for k, v in patterns}\n",
    "\n",
    "    def subsitite(self,rule, parsed_rules):\n",
    "        if not rule: return []\n",
    "        return [parsed_rules.get(rule[0], rule[0])] + self.subsitite(rule[1:], parsed_rules)\n",
    "    \n",
    "    def get_response(self,saying,rules):\n",
    "        \"\"\"\" please implement the code, to get the response as followings:\n",
    "        \n",
    "        >>> get_response('I need iPhone') \n",
    "        >>> Image you will get iPhone soon\n",
    "        >>> get_response(\"My mother told me something\")\n",
    "        >>> Talk about more about your monther.\n",
    "        \"\"\"\n",
    "        \n",
    "        for rule,response in rules.items():\n",
    "            john_pat=self.pat_match(rule.split(),saying.split())\n",
    "            if john_pat!=[]:\n",
    "                return ' '.join(self.subsitite(random.choice(response).split(),self.pat_to_dict(john_pat)))\n",
    "        \n",
    "        if not john_pat:\n",
    "            return 'I am sorry for not understanding your word. Please try again.'\n",
    "        \n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do you need xps9380 ?\n",
      "I am sorry for not understanding your word. Please try again.\n"
     ]
    }
   ],
   "source": [
    "defined_patterns = {\n",
    "    \"I need ?X\": [\"Image you will get ?X soon\", \"Why do you need ?X ?\"], \n",
    "    \"My ?X told me something\": [\"Talk about more about your ?X\", \"How do you think about your ?X ?\"]\n",
    "    }\n",
    "\n",
    "question_1_Test=Question1_simple()\n",
    "print(question_1_Test.get_response('I need xps9380',defined_patterns))\n",
    "print(question_1_Test.get_response('What?',defined_patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import jieba\n",
    "\n",
    "class Question1_muti():\n",
    "    def pat_to_dict(self,patterns):\n",
    "        return {k: ' '.join(v) if isinstance(v, list) else v for k, v in patterns}\n",
    "\n",
    "    def is_variable(self,pat):\n",
    "        return pat.startswith('?') and all(s.isalpha() for s in pat[1:])\n",
    "    \n",
    "    def is_pattern_segment(self,pattern):\n",
    "        return pattern.startswith('?*') and all(a.isalpha() for a in pattern[2:])\n",
    "    \n",
    "    def subsitite(self,rule, parsed_rules):\n",
    "        if not rule: return []\n",
    "        return [parsed_rules.get(rule[0], rule[0])] + self.subsitite(rule[1:], parsed_rules)\n",
    "    \n",
    "    fail = [True, None]\n",
    "\n",
    "    def pat_match_with_seg(self,pattern, saying):\n",
    "                \n",
    "        if not pattern or not saying: return []\n",
    "       \n",
    "        pat = pattern[0]\n",
    "       \n",
    "        if self.is_variable(pat):\n",
    "            if pattern[1:] and not saying[1:]: \n",
    "                return self.fail\n",
    "            else:\n",
    "                return [(pat, saying[0])] + self.pat_match_with_seg(pattern[1:], saying[1:])\n",
    "        elif self.is_pattern_segment(pat):\n",
    "            match, index = self.segment_match(pattern, saying)\n",
    "            \n",
    "            \"\"\"\n",
    "            加入判断条件，以识别“segment_match()把saying消耗完了，但pattern依然未匹配完的情况。”\n",
    "            \"\"\"\n",
    "            if pattern[1:] and not saying[index:]:\n",
    "                return self.fail\n",
    "            \n",
    "            return [match] + self.pat_match_with_seg(pattern[1:], saying[index:])\n",
    "        elif pat == saying[0]:\n",
    "            if pattern[1:] and not  saying[1:]: \n",
    "                return self.fail\n",
    "            else:\n",
    "                return self.pat_match_with_seg(pattern[1:], saying[1:])\n",
    "        else:\n",
    "            return self.fail\n",
    "        \n",
    "    def segment_match(self,pattern, saying):\n",
    "        seg_pat, rest = pattern[0], pattern[1:]\n",
    "        seg_pat = seg_pat.replace('?*', '?')\n",
    "\n",
    "        if not rest: return (seg_pat, saying), len(saying)    \n",
    "\n",
    "        for i, token in enumerate(saying):\n",
    "            if rest[0] == token:  \n",
    "                return (seg_pat, saying[:i]), i\n",
    "\n",
    "        return (seg_pat, saying), len(saying)\n",
    "    \n",
    "    def get_response(self,saying,rules):\n",
    "        \n",
    "        for rule,response in rules.items():\n",
    "            john_pat=self.pat_match_with_seg(rule.split(),saying.split())\n",
    "            for j in john_pat:\n",
    "                if j==None:\n",
    "                    john_pat=self.fail\n",
    "                    continue\n",
    "            if john_pat!=self.fail:\n",
    "                return ' '.join(self.subsitite(random.choice(response).split(),self.pat_to_dict(john_pat)))\n",
    "               \n",
    "        return 'I am sorry for not understanding your word. Please try again.'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image you will get dell xps 9830 soon\n",
      "Do you often feel terrible ?\n",
      "May be you can show me!\n",
      "I am sorry for not understanding your word. Please try again.\n"
     ]
    }
   ],
   "source": [
    "rule_responses = {\n",
    "    'I need ?*X':['Image you will get ?X soon', 'Why do you need ?X ?'], \n",
    "    '?*X I feel ?*Y': ['Do you often feel ?Y ?', 'What other feelings do you have?'],\n",
    "    '?*P is very good and ?*X':['May be you can show me!','What a coincidence！ ?P is very good and ?X ,too!'],\n",
    "    '?*x': ['I am sorry for not understanding your word. Please try again.']\n",
    "}\n",
    "question_1_muti_Test=Question1_muti()\n",
    "print(question_1_muti_Test.get_response('I need dell xps 9830',rule_responses))\n",
    "print(question_1_muti_Test.get_response('Ewww I feel terrible',rule_responses))\n",
    "print(question_1_muti_Test.get_response('My dog is very good and my cat is very cute',rule_responses))\n",
    "print(question_1_muti_Test.get_response('I',rule_responses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "改写以上程序，将程序变成能够支持中文输入的模式。\n",
    "*提示*: 你可以需用用到 jieba 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import jieba\n",
    "\n",
    "class Question2():\n",
    "    \"\"\"\n",
    "    lcut_processor 用来处理所有的进入字符串。\n",
    "    \"\"\"\n",
    "    def lcut_processor(self,seg_list):\n",
    "        seg_list=jieba.lcut(seg_list)\n",
    "        new_list=[]\n",
    "        i=0\n",
    "        while i<len(seg_list):\n",
    "            if seg_list[i]=='?'and i!=(len(seg_list)-1):\n",
    "                if seg_list[i+1]=='*':\n",
    "                    if seg_list[i+2].isalpha():\n",
    "                        new_list.append('?*'+(seg_list[i+2])) \n",
    "                        i+=3\n",
    "                elif seg_list[i+1].isalpha():\n",
    "                    new_list.append('?'+(seg_list[i+1]))\n",
    "                    i+=2\n",
    "                else:\n",
    "                    new_list.append(seg_list[i])\n",
    "                    i+=1\n",
    "            elif seg_list[i]==' ':\n",
    "                    i+=1\n",
    "            else:\n",
    "                new_list.append(seg_list[i])\n",
    "                i+=1\n",
    "        return new_list\n",
    "    \n",
    "    def pat_to_dict(self,patterns):\n",
    "        return {k: ' '.join(v) if isinstance(v, list) else v for k, v in patterns}\n",
    "\n",
    "    def is_variable(self,pat):\n",
    "        return pat.startswith('?') and all(s.isalpha() for s in pat[1:])\n",
    "    \n",
    "    def is_pattern_segment(self,pattern):\n",
    "        return pattern.startswith('?*') and all(a.isalpha() for a in pattern[2:])\n",
    "    \n",
    "    def subsitite(self,rule, parsed_rules):\n",
    "        if not rule: return []\n",
    "        return [parsed_rules.get(rule[0], rule[0])] + self.subsitite(rule[1:], parsed_rules)\n",
    "    \n",
    "    fail = [True, None]\n",
    "\n",
    "    def pat_match_with_seg(self,pattern, saying):\n",
    "                \n",
    "        if not pattern or not saying: return []\n",
    "       \n",
    "        pat = pattern[0]\n",
    "       \n",
    "        if self.is_variable(pat):\n",
    "            if pattern[1:] and not saying[1:]: \n",
    "                return self.fail\n",
    "            else:\n",
    "                return [(pat, saying[0])] + self.pat_match_with_seg(pattern[1:], saying[1:])\n",
    "        elif self.is_pattern_segment(pat):\n",
    "            match, index = self.segment_match(pattern, saying)\n",
    "            \n",
    "            \"\"\"\n",
    "            加入判断条件，以识别“segment_match()把saying消耗完了，但pattern依然未匹配完的情况。”\n",
    "            \"\"\"\n",
    "            if pattern[1:] and not saying[index:]:\n",
    "                return self.fail\n",
    "            \n",
    "            return [match] + self.pat_match_with_seg(pattern[1:], saying[index:])\n",
    "        elif pat == saying[0]:\n",
    "            if pattern[1:] and not  saying[1:]: \n",
    "                return self.fail\n",
    "            else:\n",
    "                return self.pat_match_with_seg(pattern[1:], saying[1:])\n",
    "        else:\n",
    "            return self.fail\n",
    "        \n",
    "    def segment_match(self,pattern, saying):\n",
    "        seg_pat, rest = pattern[0], pattern[1:]\n",
    "        seg_pat = seg_pat.replace('?*', '?')\n",
    "\n",
    "        if not rest: return (seg_pat, saying), len(saying)    \n",
    "\n",
    "        for i, token in enumerate(saying):\n",
    "            if rest[0] == token:  \n",
    "                return (seg_pat, saying[:i]), i\n",
    "\n",
    "        return (seg_pat, saying), len(saying)\n",
    "\n",
    "    def is_Chinese(self,sentence):\n",
    "        for word in sentence:\n",
    "            for ch in word:\n",
    "                if '\\u4e00' <= ch <= '\\u9fff':\n",
    "                    return True\n",
    "        return False\n",
    "    def get_response(self,saying,rules):\n",
    "\n",
    "        for rule,response in rules.items():\n",
    "            john_pat=self.pat_match_with_seg(self.lcut_processor(rule),self.lcut_processor(saying)) \n",
    "            for j in john_pat:\n",
    "                if j==None:\n",
    "                    john_pat=self.fail\n",
    "                    continue\n",
    "            if john_pat!=self.fail:\n",
    "                Reply=self.subsitite(self.lcut_processor(random.choice(response)),self.pat_to_dict(john_pat))\n",
    "                if self.is_Chinese(Reply):\n",
    "                    return ''.join(Reply)\n",
    "                else:\n",
    "                    return ' '.join(Reply)\n",
    "        return 'I am sorry for not understanding your word. Please try again.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你想要XPS 9380吗？\n",
      "What a coincidence ！ My dog is very good and my cat is very cute , too !\n"
     ]
    }
   ],
   "source": [
    "question2_test=Question2()\n",
    "rule_responses = {\n",
    "    'I need ?*X':['Image you will get ?X soon', 'Why do you need ?X ?'], \n",
    "    '?*X I feel ?*Y': ['Do you often feel ?Y ?', 'What other feelings do you have?'],\n",
    "    '?*P is very good and ?*X':['Maybe you can show me!','What a coincidence！?P is very good and ?X, too!'],\n",
    "    '?*x喜欢?*y': ['喜欢?y的哪里？', '?y有什么好的呢？', '你想要?y吗？'],\n",
    "    '?*x': ['I am sorry for not understanding your word. Please try again.']\n",
    "}\n",
    "print(question2_test.get_response('我喜欢XPS 9380',rule_responses))\n",
    "print(question2_test.get_response('My dog is very good and my cat is very cute',rule_responses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "历史记录模式，在完成一次对话之后，将模式中匹配到的?X关键词字典储存下来，并添加到模式中，以呈现一种机器人记忆的方式。\n",
    "如：\n",
    "    人：我喜欢猫\n",
    "    机器：我也是。\n",
    "    人：我喜欢狗\n",
    "    机器：但你上次说你喜欢猫。\n",
    "    \n",
    "在与一个人对话的同时，机器为这个人建立语料库，并储存这些历史信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 这样的程序有什么优点？有什么缺点？你有什么可以改进的方法吗？ \n",
    "\n",
    "    答：优点是，程序应答速度快，在面对一些“有规律的、反复的”问答时，一旦匹配到了特定的规则，机器人可以快速的完成问答任务。\n",
    "        缺点是，规则是死的，出现规则外的问答时，直接失去作用。其次规则的增改删查依然需要人类来进行操作。\n",
    "        \n",
    "        我个人认为可以通过语料库的方式储存对话，在面对同一个人的问答时，机器人可以搜索历史记录来“获得对话历史信息”以增加对话的丰富程度。在对话失败的记录(\"I don't understand you\")中，可以用聚类的方式向规则库增加新的规则。\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 什么是数据驱动？数据驱动在这个程序里如何体现？\n",
    "\n",
    "   答：个人的理解是，新的数据能够影响机器进行决策，就已经是数据驱动了。再往深了说，机器能够从数据中获得“信息”，并根据这个信息来进行决策，也是数据驱动的一种体现。\n",
    "   \n",
    "       在这个程序中，我们的输入语句就是数据，机器处理了这份数据(匹配规则，分割语句等)，并作出不同的决策(回答)，就是体现了数据驱动的思想。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 数据驱动与 AI 的关系是什么？ \n",
    "    \n",
    "    答：AI的学习能力，来自于数据驱动。\n",
    "        我们的程序设计让AI程序有了能够处理并提取信息的能力，然后AI不断的处理数据，并从中提取信息，进行学习，这一切的根源就是数据。\n",
    "        没有新新新的数据，AI的处理提取能力再强大，也无法继续学习到新的知识，准确率不再上升。\n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
