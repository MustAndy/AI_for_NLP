{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key points\n",
    "+ 机器学习的基本概念\n",
    "+ 数据分布、数据预处理\n",
    "+ Linear Regression, Logstic Regression\n",
    "+ Gredient Descent\n",
    "+ 作业练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础概念复习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 机器学习方法主要用在什么特点的常见下？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 1.数据量大 2.有标签的数据可用作监督学习。 3.很难去定义规则。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 提出 3 个你认为使用了机器学习方法的现实场景."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 1.用户个性推荐 2.垃圾邮件分类 3.面部识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 提出 3 个你认为可以使用机器学习但是还没有使用机器学习方法的场景. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 1.船舶调度 2.医学诊断问题，有些疾病已经开始使用ML了。 3.电脑故障诊断！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 什么是“模型”？ 为什么说“All models are wrong, but some useful”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 现实问题的抽象。在抽象简化问题的过程中，我们总是会遗失一些特征、参数，而往往这些参数都是决定结果的因素之一，所以模型都有局限性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Classification 和 Regressionu主要针对什么？ 有什么区别？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Classification往往用于标签分类任务；Regression一般用于数值预测。分类任务所有的标签都是等值不同，回归的预测值是有相互关系的区分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. precision， recall，f1, auc 分别是什么意思？ 假设一个城市有 10000 人，有 30 个犯罪分子，警察抓到了 35 个人，其中 20 个是犯罪分子，请问这个警察的 precision, recall, f1,auc 分别是什么？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Auc针对全局结果数量、Pre针对预测为真的预测结果、Rec针对正确答案的预测结果、f1是一种综合考量。\n",
    "\n",
    "TP-将正预测为真，FN-将正预测为假，FP-将假预测为真，TN-将假预测为假。\n",
    "\n",
    "$$ Auc = \\frac {TP+TN} {TP+FN+FP+TN} $$\n",
    "\n",
    "$$ Pre = \\frac {TP} {TP+FP} $$\n",
    "\n",
    "$$ Rec = \\frac {TP} {TP+FN} $$\n",
    "\n",
    "$$ F1  = \\frac {2*(Pre*Rec)} {(Pre+Rec)}$$\n",
    "\n",
    "抓坏蛋 抓35个人，20个是真罪犯，5个是无辜的，剩下10个是冤枉抓错的？\n",
    "\n",
    "Pre = 20/(20+15)=4/7\n",
    "\n",
    "Rec = 20/(20+9950)=2/997\n",
    "\n",
    "f1 = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 请提出两种场景，第一种场景下，对模型的评估很注重 precision, 第二种很注重 recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:搜索任务中，当你要获得精准的结果时，注重pre；\n",
    "\n",
    "但你要获得更加发散的结果时，注重recall。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 什么是 Overfitting， 什么是 Underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 过拟合：模型过于复杂/数据量过少，以至于完全拟合训练数据而导致对于未来的预测出现较为严重的错误。\n",
    "\n",
    "欠拟合：模型简单，数据量过大，无法从训练集中得出规律或特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Lazy-Learning， Lazy在哪里？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Median， Mode， Mean分别是什么？ 有什么意义？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 中位数、众数、均值。三者在某种程度上都能概括一组数据的模式；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Outlinear（异常值、离群值）是什么？ 如何定义？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:一般指高于/低于某个标准而被略过的数据；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Bias 和 Variance 有什么关系？ 他们之间为什么是一种 tradeoff 的？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 互为相反的两种描述；过于极端的两种情况都会导致模型的测试效果低下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Train， Validation，Test 数据集之间是什么关系？ 为什么要这么划分？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 训练、验证、测试数据集之间要求不能有重复数据；train、validation用于训练过程中，两者的loss用来衡量训练时模型的好坏。validation和test都用于测试模型在没见过的数据上的表现好坏。因为train和validation在训练中模型‘见过’；所以在最后要用test来测试总效率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Supervised Learning 的 Supervised 体现在什么地方？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 训练数据有标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Linear Regression 中，什么是“线性关系”？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 模型表达式中所有的X的幂次都是相等的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Linear Regression中，Loss 函数怎么定义的？ 为什么要写成这样？ 什么是凸函数？ 优化中有什么意义？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 模型到数据的距离，我们用下面这个公式来定义线性回归的Loss。 $$ Loss_n = \\frac {1}{n} \\sum (y_i - f(x_i))^2 $$\n",
    "\n",
    "这样写可以让Loss形成一个凸函数。\n",
    "\n",
    "凸函数在某个区间内的局部最小值等于全局最小值； 老师上课例子：打方向盘只往一个方向打。\n",
    "\n",
    "优化中的目标就是可以到达凸函数的最低点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. 简述Gradient Descent的过程，以 $y = -10 * x^2 + 3x + 4 $ 为例，从一个任一点 $ x = 10 $ 开始，如何根据 Gradient Descent 找到最值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 选择不错步长为0.05，y导数为：$$\\dot y=-20x+3$$\n",
    "\n",
    "\n",
    "| iteration  | X             |y导  | y             |\n",
    "| --------- | ------------------ |------------------|------------------|\n",
    "| 1 |10| -197 |-996 |\n",
    "| 2 |0.15|0 | 4.225|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. 一般在机器学习数量时，会做一个预处理（Normalization）， 简述 Normalization 的过程，以及数据经过 Normalization之后的平均值和标准差的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 使数据的的绝对值变成某种相对值关系；平均值变为无限接近于0，标准差为1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. Logstic Regression 的 Logstic 是什么曲线，被用在什么地方？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 是用指数次方构造的Y值位于0-1之间的函数。0-1的性质让他可以预测概率分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. Logstic Regression 的 Loss 函数 Cross Entropy 是怎么样的形式？ 有什么意义？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans：p为正确答案，q为模型输出答案\n",
    "$$ H(p,q) = -\\sum_{i=0}^n y'_ilog(y_i) $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问题实战"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题描述： 在新闻出版业中一个常常的问题就是新闻版权抄袭，所以我们现在为了避免这个事情，需要建立一个模型，判断这个文章是不是由某个新闻出版单位出版的。 在我们这个问题里，我们需要建立一个模型，该模型接受一个作为文本的输入，然后判断该文本是不是由“新华社”发布的。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enviroment: \n",
    "\n",
    "+ Python 3.6\n",
    "+ numpy \n",
    "+ scikit learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**请在 pycharm 中运行程序，该处只作为关键信息的记录。 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 问那么此问题应该用机器学习方法？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans：逻辑回归：先判断输入文本有多少概率是新华社新闻，然后再根据定下的标准来分类。\n",
    "传统CNN分类器：根据输入分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 问什么要对文本进行向量化？ 如何进行文本向量化表示？ （请使用tfidf 或者词向量）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 要将文本用向量数据表征，然后才能进行训练；可以使用doc2Vec 词向量、tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hint: 如果你使用 tfidf，则需要 scikit learning 如果你需要词向量，则需要 gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 请对数据进行Preprocessing, Normalization 操作\n",
    "（你需要在 Preprocssing 的时候，把文章开头的“新华社”3 个字去掉。如果不去掉，会出现什么问题？）\n",
    "\n",
    "对矩阵进行了最大最小归一化操作将句向量的权重矩阵的值调整到[-1,1]之间。\n",
    "去掉新华社之后，能够去掉这个关键词对句向量的影响；让模型能够更加专注于句子的内容而不是‘新华社’的这个关键词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 请确定模型的 Baseline 以及确定评测指标（Evaluation）.\n",
    "\n",
    "超过80%的概率就视作抄袭了新华社的新闻。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 尝试不同的模型、不同的参数，观察结果变化。 \n",
    "\n",
    "改变了学习速率，影响模型的收敛速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 依据模型的表现，进行参数调节。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据加载类：dataLoading\n",
    "\n",
    "+init：入口初始化函数\n",
    "\n",
    "+loadCsvfile：加载原数据的csv文件。\n",
    "\n",
    "+loadContent；加载已经解析好的txt文件，若是没有，则解析csv文件并保存文本到txt文件。\n",
    "\n",
    "+loadModel：加载已经训练好的doc2vev模型文件，若是没有，则通过上面的content训练出新的模型并保存。\n",
    "\n",
    "+loadTest：测试已加载的模型和内容。\n",
    "\n",
    "————————————————————————————\n",
    "\n",
    "矩阵数据准备类：inputData\n",
    "\n",
    "+init：入口初始化函数，将加载好的model数据放入类中的X,Y里。\n",
    "\n",
    "+prepare：先将所有数据X中的正数据随机的丢弃一部分，最终使得正负数据的比例为1.5:1。然后对剩下的数据进行正则化操作，使得矩阵的所有值落在0-1之间。然后根据1:9的比例分割为训练集与验证集，最终返回训练集与验证集的XY数组。\n",
    "\n",
    "+normalization：正则化方法，返回正则化之后的矩阵。\n",
    "\n",
    "+percentage：打印训练集中，正负样本的比例。\n",
    "\n",
    "————————————————————————————\n",
    "\n",
    "训练用了逻辑回归的基本代码，通过计算损失函数的导数来计算梯度的大小，然后降低损失函数。\n",
    "\n",
    "因为从0开始训练，所以一开始的学习速率可以调的很大，然后随着loss不再下降，我们可以推测在loss的最小值之间震荡，我们就适当的调低学习速率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:45:09.513336Z",
     "start_time": "2019-06-15T09:45:09.132983Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:45:10.111996Z",
     "start_time": "2019-06-15T09:45:09.516732Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re\n",
    "import pandas as pd\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "def cut(string): return ' '.join(jieba.cut(string))\n",
    "symbol='[^((新华社)|\\r|\\n|)]'\n",
    "#print(symbol)\n",
    "def token(string):\n",
    "    return ''.join(re.findall(symbol,string))\n",
    "\n",
    "\n",
    "class dataLoading():\n",
    "      \n",
    "    news=None\n",
    "    content=None\n",
    "    model=None\n",
    "    newSource=None\n",
    "    newLabel=None\n",
    "    \n",
    "    def __init__(self,input_vector_size):\n",
    "        self.loadCsvfile()\n",
    "        self.loadContent()\n",
    "        self.loadModel(self.content,input_vector_size)\n",
    "    \n",
    "    def loadCsvfile(self):\n",
    "        filepath = 'D:/senior/aiCourse/datasource/sqlResult_1558435.csv'\n",
    "        self.news = pd.read_csv(filepath, encoding='gb18030')\n",
    "        self.newSource = self.news['source'].tolist()\n",
    "        return self.news\n",
    "    \n",
    "    def loadContent(self):\n",
    "        self.newLabel = []\n",
    "        news_content = []\n",
    "        #self.newSource=[]\n",
    "        i=0\n",
    "        \n",
    "        if not os.path.exists('D://senior/aiCourse/dataSource/news.txt'):\n",
    "            news_content = self.news['content'].tolist()\n",
    "            news_content = [token(str(n)) for n in news_content]\n",
    "            self.content = [''.join(n) for n in news_content]\n",
    "            news_content = [cut(n) for n in news_content]\n",
    "            with open(\"D://senior/aiCourse/dataSource/news.txt\",'w',encoding='gb18030') as inputFile:\n",
    "                for line in news_content:\n",
    "                    inputFile.write(line+'\\n')\n",
    "        self.content = []\n",
    "        with open('D://senior/aiCourse/dataSource/news.txt',encoding='gb18030')as f:\n",
    "            for line in f.readlines():\n",
    "                if line.strip() == 'nan' :\n",
    "                    i+=1\n",
    "                    continue\n",
    "                else:            \n",
    "                    self.content.append(line[:-1])\n",
    "                    if self.newSource[i]=='新华社':\n",
    "                        self.newLabel.append(1)\n",
    "                    else:\n",
    "                        self.newLabel.append(0)\n",
    "                    i+=1                    \n",
    "        return self.content\n",
    "    \n",
    "    def loadModel(self,news_content,input_vector_size):\n",
    "        \n",
    "        if not os.path.exists(\"./doc2vec-\"+str(input_vector_size)+\".txt\"):\n",
    "            documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(news_content)]\n",
    "            model = Doc2Vec(documents, vector_size=input_vector_size, window=2, min_count=1, workers=7)\n",
    "            model.save(\"./doc2vec-\"+str(input_vector_size)+\".txt\")\n",
    "            \n",
    "        self.model = Doc2Vec.load(\"./doc2vec-\"+str(input_vector_size)+\".txt\")\n",
    "        return self.model\n",
    "    \n",
    "    def loadingTest(self):\n",
    "        print(self.model.docvecs.most_similar(16))\n",
    "        print(self.content[16]+'\\n')\n",
    "        print(self.content[32])\n",
    "    \n",
    "\n",
    "    #def loadTestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:49:19.116929Z",
     "start_time": "2019-06-15T09:45:10.113901Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(58, 0.7649303674697876), (5695, 0.7483332753181458), (34, 0.7408505082130432), (23, 0.7332472801208496), (32, 0.7308980226516724), (5673, 0.7249002456665039), (5778, 0.7190104722976685), (5987, 0.7175047397613525), (53, 0.7165408730506897), (5601, 0.7150400876998901)]\n",
      "九成 以上 的 源 包用 逐位 对应 的 方式 构建 ， 未来 版本 的   Debian   还 将 提供 验证 包 的 工具 和 元 数据 ； X   显示 系统 不再 需要   root   权限 运行 ； GnuPG   经典 版本 将 被 淘汰 ， 引入 的 现代 版本 增加 了 椭圆 曲线 加密 ， 改进 默认设置 ， 模块化 架构 ， 改进 智能卡 支持 ； 改进   UEFI   支持 等 。 软件 方面 的 变化 包括 ： Apache   2.4 . 25 、 Chromium   59.0 . 3071.8 、 Firefox   45.9 、 GIMP   2.8 . 18 、 更版 的   GNOME   3.22 、 GnuPG   2.1 、 LibreOffice   5.2 、 Linux   4.9 、 MariaDB   10.1 、 PHP   7.0 .... 更 详细 清单 见 发布公告 。\n",
      "\n",
      "其他 规格 方面 ， 搭载 飞思 卡尔 IMX6SL 处理器 ， 内存 512MB ， 存储 8GB ， 采用 定制 版 系统 ， 低耗 稳定 ， 阅读 流畅 。 提供 3.5 mm 耳机 接口 ， 支持 听书 功能 。 内容 方面 ， 可 无缝 对接 QQ 阅读 、 起点 中文网 等 正版 书籍 平台 ， 支持 QQ 、 微信 登录 ， 自动 云 同步 QQ 阅读 APP 书架 和 阅读 进度 。\n"
     ]
    }
   ],
   "source": [
    "data = dataLoading(1000)\n",
    "data.loadingTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:49:19.129741Z",
     "start_time": "2019-06-15T09:49:19.118828Z"
    }
   },
   "outputs": [],
   "source": [
    "class inputData():\n",
    "    \n",
    "    X=[]\n",
    "    Y=[]\n",
    "\n",
    "    def __init__(self,data):\n",
    "        length = len(data.newLabel)\n",
    "        for i in range(0,length):\n",
    "            self.X.append(data.model.docvecs.vectors_docs[i])\n",
    "            self.Y.append(data.newLabel[i])           \n",
    "            \n",
    "    def prepare(self):\n",
    "        x_training = []\n",
    "        y_training = []\n",
    "        x_testing = []\n",
    "        y_testing = []\n",
    "        temp = list(zip(self.X, self.Y))\n",
    "        random.shuffle(temp)\n",
    "        self.X[:], self.Y[:] = zip(*temp)\n",
    "        #print(len(self.X))\n",
    "       # print(len(self.Y))\n",
    "        temp = len(self.Y)-1\n",
    "        for i in range (0,75000):\n",
    "            tempNum = random.randint(1,temp)\n",
    "            if self.Y[tempNum]==1:\n",
    "                del self.X[tempNum]\n",
    "                del self.Y[tempNum]\n",
    "                temp-=1\n",
    "                \n",
    "        temp = list(zip(self.X, self.Y))\n",
    "        random.shuffle(temp)\n",
    "        self.X[:], self.Y[:] = zip(*temp)\n",
    "        \n",
    "        length = len(self.X)\n",
    "        for i in range(0,length):\n",
    "            self.X[i]=self.normalization(self.X[i])       \n",
    "        \n",
    "        length = int(len(self.X)*9/10)-1\n",
    "        x_training = np.array(self.X[:length])\n",
    "        y_training = np.array(self.Y[:length])\n",
    "        \n",
    "        x_testing = np.array(self.X[length:])\n",
    "        y_testing = np.array(self.Y[length:])\n",
    "        \n",
    "        return x_training,y_training,x_testing,y_testing\n",
    "        \n",
    "        \n",
    "    def normalization(self,arr):\n",
    "        #print(arr)\n",
    "        # normalizing doc2vec\n",
    "        m = np.mean(arr)\n",
    "        h = max(arr)\n",
    "        l = min(arr)\n",
    "        result = [(float(i) - m) / (h - l) for i in arr]\n",
    "        result = np.array(result)\n",
    "        return result\n",
    "    \n",
    "    def percentage(self,Y_test):\n",
    "        pos = 0\n",
    "        negi=0\n",
    "        for i in Y_test:\n",
    "            if i==1:\n",
    "                pos+=1\n",
    "            if i==0:\n",
    "                negi+=1\n",
    "        print(\"pos/all:{}\".format(pos/len(Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:50:14.508593Z",
     "start_time": "2019-06-15T09:49:19.132221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos/all:0.6540151817818618\n"
     ]
    }
   ],
   "source": [
    "inputdata=inputData(data)\n",
    "X_train,Y_train,X_test,Y_test = inputdata.prepare()\n",
    "inputdata.percentage(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:50:14.766301Z",
     "start_time": "2019-06-15T09:50:14.510522Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:50:14.773768Z",
     "start_time": "2019-06-15T09:50:14.769330Z"
    }
   },
   "outputs": [],
   "source": [
    "def weightInitialzation(n_features):\n",
    "    w=np.zeros((1,n_features))\n",
    "    b=0\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:50:14.782827Z",
     "start_time": "2019-06-15T09:50:14.776244Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid_activation(result):\n",
    "    final_result = 1/(1+np.exp(-result))\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:50:14.789698Z",
     "start_time": "2019-06-15T09:50:14.784272Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_optimize(w,b,X,Y):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    #prediction\n",
    "    final_result = sigmoid_activation(np.dot(w,X.T)+b)\n",
    "    Y_T=Y.T\n",
    "    cost = (-1/m)*(np.sum((Y_T*np.log(final_result))+((1-Y_T)*(np.log(1-final_result)))))\n",
    "    \n",
    "    #gradient calculation\n",
    "    dw = (1/m)*(np.dot(X.T,(final_result-Y.T).T))\n",
    "    db=(1/m)*(np.sum(final_result-Y.T))\n",
    "    \n",
    "    grads = {'dw':dw,'db':db}\n",
    "    return grads,cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:50:14.798945Z",
     "start_time": "2019-06-15T09:50:14.791186Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_training(w,b,X,Y,learning_rate,no_iterations):\n",
    "    costs = []\n",
    "    for i in range (no_iterations):\n",
    "        grads,cost = model_optimize(w,b,X,Y)\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        w=w-(learning_rate*(dw.T))\n",
    "        b=b-(learning_rate*db)\n",
    "\n",
    "        if(i%100 ==0):\n",
    "            costs.append(cost)\n",
    "        if len(costs)>2 and costs[-1]/costs[-2]<0.05:\n",
    "            learning_rate = learning_rate/2\n",
    "    coeff={'w':w,'b':b}\n",
    "    gradient={'dw':dw,'db':db}\n",
    "    \n",
    "    return coeff,gradient,costs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:50:14.805347Z",
     "start_time": "2019-06-15T09:50:14.800358Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(final_pred,m):\n",
    "    y_pred = np.zeros((1,m))\n",
    "    for i in range(final_pred.shape[1]):\n",
    "        if final_pred[0][i]>0.5:\n",
    "            y_pred[0][i]=1\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:50:34.993725Z",
     "start_time": "2019-06-15T09:50:14.806805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized weights [[-4.46723360e-01  2.56186645e-01  5.80097415e-01 -1.66462991e-01\n",
      "   1.51920313e-01 -1.82510329e-02  3.72074886e-01 -3.43506597e-01\n",
      "  -3.30565295e-01  3.47639025e-01  1.80941405e-01  1.84422003e-01\n",
      "  -1.90742720e-01  2.13733606e-01  2.02649109e-01  2.48416296e-01\n",
      "  -6.06390093e-02  1.01429322e-01  1.11057668e-01 -4.25522837e-02\n",
      "   3.21136108e-02  6.88707197e-04 -3.44857408e-02  3.96030503e-02\n",
      "  -1.99804497e-02  1.73149146e-01  9.10795420e-04 -1.72466968e-01\n",
      "   2.55407021e-02 -4.95300945e-02 -1.28023656e-02  1.79327567e-02\n",
      "  -3.52411028e-02 -5.22784570e-02 -1.00416048e-01 -2.29896277e-01\n",
      "  -2.01289899e-01 -1.30707270e-01 -5.71155587e-02  2.38008887e-01\n",
      "  -6.02463579e-02 -2.01065586e-01 -4.64095850e-02 -1.73585293e-01\n",
      "  -3.33909499e-01 -4.43106923e-02  3.11975066e-01  6.63332327e-02\n",
      "  -4.23416707e-02  5.33850549e-02  1.06881322e-01  8.18255750e-03\n",
      "  -1.11646005e-01  1.01699381e-02 -6.33084262e-02  1.44321729e-02\n",
      "   2.30447653e-02 -7.79013479e-03  2.32972041e-01 -9.30432918e-02\n",
      "   1.95427302e-01 -1.47514669e-01 -1.26401591e-01 -1.03839188e-01\n",
      "   1.07025810e-01 -4.91514589e-02 -3.86100249e-03 -1.04498809e-01\n",
      "   1.19358345e-01 -7.50293980e-02  1.70663269e-01  8.58572052e-02\n",
      "  -9.66510164e-02 -1.07365140e-01 -2.90317729e-02  2.26970115e-01\n",
      "   4.84600149e-02  1.69562446e-01  1.90752513e-02  7.92807764e-02\n",
      "  -8.07273454e-02  7.58712910e-02  2.94342047e-02  5.99152819e-02\n",
      "   9.08121608e-02  8.90697457e-02 -3.63595150e-02  1.60267772e-01\n",
      "  -6.55861732e-02  4.38507155e-02  7.81597222e-02 -1.76926773e-01\n",
      "   4.45800413e-02 -3.77147853e-02  1.38185694e-01  9.08281424e-02\n",
      "   1.43969756e-01  1.24360542e-01  4.72054406e-04  7.82426237e-02\n",
      "   1.09303495e-01  9.32147937e-02  9.72402320e-02 -2.99626184e-02\n",
      "   6.72575966e-03  9.63865222e-02  2.03125871e-02 -1.17231731e-01\n",
      "   1.47888730e-01  4.30815694e-02  2.17997721e-02  1.82363380e-02\n",
      "  -8.76419411e-02 -1.47754204e-01  1.11004243e-01 -5.82827244e-02\n",
      "   5.91373595e-03 -4.34319460e-02 -4.24352028e-02 -2.69983750e-02\n",
      "   2.07815311e-01 -4.46698819e-02 -1.83995945e-02 -1.69617830e-01\n",
      "   1.06679764e-01  4.59753439e-02 -6.92594068e-02 -6.26304165e-02\n",
      "  -5.73863640e-02 -7.21189434e-02 -6.77363335e-02  3.88237650e-02\n",
      "  -1.78814314e-01 -1.20753111e-01  5.42957557e-02  1.07343828e-02\n",
      "  -3.27420403e-02  4.99474186e-02  4.52418639e-02 -5.40971163e-02\n",
      "   6.76813956e-02 -2.21486361e-02 -2.59507517e-02  1.88149268e-01\n",
      "   9.68562088e-03  1.93781272e-01  2.18173003e-02  1.70577714e-01\n",
      "   3.04043108e-02 -1.41478822e-01 -3.49996805e-03  6.17163432e-02\n",
      "  -1.18909824e-02 -3.85459658e-02 -2.57223437e-02 -9.42143055e-02\n",
      "  -4.44901109e-03 -1.48597680e-01 -2.47918341e-01 -1.77954048e-01\n",
      "  -6.74075625e-02 -1.70675598e-02 -1.56036240e-01  4.22944228e-02\n",
      "   2.01064478e-01  2.61821730e-01 -1.01277607e-01 -3.55558928e-02\n",
      "   5.72054597e-02 -1.22463380e-01  1.41395866e-01  3.14145184e-01\n",
      "  -8.70151343e-02 -1.29994076e-01  1.54557870e-01 -2.85664220e-02\n",
      "   5.57724169e-02  5.61973157e-02  6.26872530e-02  8.58585526e-02\n",
      "  -5.82659309e-02 -2.19006282e-01 -1.16142183e-01  4.32058470e-02\n",
      "  -4.70409069e-02 -1.69501226e-01 -4.44630018e-03  1.32494670e-01\n",
      "  -2.40472027e-01 -1.25944032e-01  1.82647466e-02  9.78311116e-02\n",
      "  -3.43214057e-02 -1.50053232e-01  8.59461095e-02  4.63769914e-03\n",
      "  -1.72402502e-01 -1.41604344e-01 -1.00287662e-01 -7.48722406e-02\n",
      "  -7.48824625e-02 -5.47558484e-02  2.94247447e-02 -9.72762334e-02\n",
      "  -6.16433640e-02 -1.26124546e-01  1.48277960e-01  1.40657587e-01\n",
      "  -1.08543919e-02  3.46476950e-02 -8.28277345e-03  2.73359953e-02\n",
      "   1.54632710e-01  9.73161921e-02 -1.47493109e-01  3.16761607e-02\n",
      "   2.40916505e-01  1.02350271e-01 -1.28367588e-02 -1.54502963e-01\n",
      "   1.98947462e-01 -1.36106803e-01 -1.61205555e-02 -4.12232585e-02\n",
      "  -7.10608502e-02 -3.57249060e-02  8.70728571e-02  4.64253979e-02\n",
      "  -4.00660269e-02 -1.98588191e-01 -9.78353271e-02  2.81948665e-02\n",
      "   1.63513641e-01 -1.73638009e-01  1.30723635e-01  7.04757894e-02\n",
      "   2.45023994e-01 -1.28469074e-01 -7.00600054e-02  5.96437957e-02\n",
      "  -1.44227224e-01  1.03725883e-01  8.94914818e-02 -1.69892453e-02\n",
      "  -1.01987613e-02 -2.24952782e-01 -1.52384893e-02  9.07367130e-02\n",
      "  -1.44825393e-01  4.48786559e-03 -1.59588811e-01 -1.83949237e-01\n",
      "   2.02975460e-01  7.36728391e-02 -4.86095216e-02  9.26952219e-02\n",
      "  -1.43983235e-02 -8.17406349e-02  1.87576936e-01  9.82084687e-02\n",
      "   5.40315575e-02 -1.17868712e-01  3.01861831e-02  6.63583338e-02\n",
      "  -2.45262804e-01 -4.91360689e-02  1.11458095e-01  6.29690900e-02\n",
      "   1.37756840e-03 -1.63766927e-01 -1.00806993e-01  9.63762308e-02\n",
      "  -5.72421220e-02 -1.52049534e-01  3.05092295e-01  1.75411689e-01\n",
      "  -4.80222435e-02  2.52711582e-01 -1.00478971e-01  3.74549135e-01\n",
      "  -5.06804443e-01  1.09015028e-01 -7.16667950e-02  3.39638281e-01\n",
      "   8.21596353e-03  2.64867767e-01  3.24513299e-02  7.91742969e-02\n",
      "   3.37440118e-01 -7.24487083e-02 -1.96135445e-01 -1.72862395e-01\n",
      "   7.58308635e-02  3.66144255e-02  1.18693156e-01  6.02230407e-02\n",
      "  -9.47289666e-02  2.73165779e-01  1.94071493e-02 -1.25827254e-01\n",
      "  -1.47069851e-02 -9.59162073e-02  2.08550526e-01 -1.66451311e-02\n",
      "   2.24017386e-02 -5.08525213e-03 -1.22489041e-01  1.11453754e-01\n",
      "  -5.21896961e-02 -1.07837833e-01 -1.62576032e-01  1.35622989e-01\n",
      "  -9.51237875e-02 -4.44980704e-02 -5.65613578e-02  5.72791631e-03\n",
      "  -1.34360511e-01 -1.42283059e-02 -1.20033152e-01 -1.17885669e-01\n",
      "  -8.28641218e-02  1.74935447e-01  1.19340989e-01 -2.23739251e-01\n",
      "  -8.39282127e-02 -1.49567197e-01  8.37230587e-02 -3.98000160e-02\n",
      "  -6.97520774e-02 -1.24634729e-01 -8.88820443e-02  2.56880984e-01\n",
      "   1.32969856e-01 -2.64079890e-01 -1.63202461e-01  6.31396287e-02\n",
      "   1.89771864e-01 -1.23820040e-01 -5.30255099e-02  1.95340680e-01\n",
      "   1.04715617e-01 -4.79314422e-02 -8.98003369e-02  1.50678155e-02\n",
      "  -3.97753473e-02  1.29426676e-01 -9.07143414e-03 -6.79844432e-02\n",
      "  -2.68835441e-01 -7.69398133e-02  1.23796980e-01 -4.74771641e-02\n",
      "   5.99973034e-02  1.20830011e-01  2.00360589e-02 -1.40625460e-01\n",
      "  -1.30929103e-01 -6.59621679e-02  1.07917461e-02 -4.25240337e-02\n",
      "  -1.66108780e-02 -1.27735026e-01  5.77858677e-02 -2.12650237e-01\n",
      "  -1.01114733e-01 -1.85391366e-02  3.44430385e-02  5.47356712e-03\n",
      "   2.13192240e-01 -6.97133977e-02  9.79942632e-02  1.75007834e-01\n",
      "  -3.10099003e-02 -2.46860983e-01  1.71617017e-01  2.54216219e-01\n",
      "  -8.63374459e-02 -3.05248928e-02 -5.54843442e-02  1.02996217e-01\n",
      "   1.20633437e-01 -5.63448351e-02  1.84989202e-04 -3.83865593e-03\n",
      "   5.41877179e-02  2.19176180e-02  2.61655216e-01 -2.22522786e-02\n",
      "  -2.43053974e-01 -2.46914371e-01  2.01063738e-01  1.34630242e-01\n",
      "  -6.67430278e-02  8.65110959e-02  1.90353722e-01  5.05854950e-02\n",
      "  -1.31393166e-01  7.51529902e-02 -1.27053797e-01 -2.19884926e-01\n",
      "   3.25314905e-01  5.62905904e-02  3.31975441e-01 -9.06439678e-02\n",
      "  -3.99069709e-03 -6.70945508e-02  2.26130716e-01 -8.00799480e-02\n",
      "   2.58828296e-01 -1.38178232e-01  2.10046969e-02  3.07275193e-02\n",
      "   3.02654778e-01 -1.61028208e-01  1.06874319e-01  1.32285682e-01\n",
      "  -3.44074394e-02 -2.27152529e-01 -3.60502153e-02  2.01851630e-01\n",
      "   1.14702872e-01 -2.95396274e-01 -3.38055052e-02 -2.50939967e-02\n",
      "  -2.75713339e-01  2.42294719e-01  1.88984984e-01  3.51224951e-01\n",
      "   7.41907527e-02  3.83305472e-01  2.17135549e-01 -3.04317079e-02\n",
      "   2.56995085e-01 -4.62153224e-02  2.15600274e-01  1.59017862e-01\n",
      "   1.17011434e-02  2.32089010e-02 -8.49858641e-02  3.73114034e-01\n",
      "   3.15452408e-01 -6.21174246e-02  1.80686124e-01 -2.32778647e-02\n",
      "  -6.19005471e-02  1.54404730e-01  1.42263745e-01 -1.78507451e-01\n",
      "   1.02327451e-01 -2.69450384e-02  2.48089484e-01  5.18214213e-01\n",
      "   7.15631086e-02 -3.41095933e-01  4.11789745e-02  8.54434638e-02\n",
      "  -2.50134163e-02  3.24111685e-01  2.32497627e-01  1.28566872e-01\n",
      "   3.93765028e-01  1.10782485e-01 -2.81219052e-01  2.33605909e-01\n",
      "  -7.99687678e-02 -3.38006773e-02 -3.30531262e-02  1.97639525e-01\n",
      "   2.80795466e-01  7.10975227e-02 -2.01076977e-01  1.01255226e-02\n",
      "  -3.29719217e-01 -1.39441369e-01 -1.67006507e-01  1.15421904e-02\n",
      "   4.81766989e-02 -4.90865839e-02  3.20499925e-02 -2.56395363e-01\n",
      "  -1.00096779e-04  1.93038638e-01 -1.64363036e-01 -3.11473325e-01\n",
      "  -2.00813559e-01  8.70558646e-02  1.09521658e-01 -1.02931116e-01\n",
      "   3.70219490e-02  8.99051062e-02  4.35785331e-02  4.22859585e-02\n",
      "   4.00731059e-02  1.19179717e-02 -1.82327719e-01 -5.12882330e-02\n",
      "   7.55692862e-02  1.45181597e-02 -1.37916493e-02  8.32949052e-02\n",
      "   2.52705071e-01 -2.06070567e-02 -9.78817816e-02 -1.16372495e-01\n",
      "  -2.56499374e-01  1.17075765e-01 -1.68648436e-01  1.87191101e-01\n",
      "  -2.30197967e-01  1.98932841e-01 -4.42276696e-01 -7.42682695e-02\n",
      "   1.38438698e-01 -2.02065555e-01  1.54519410e-02 -1.13564786e-01\n",
      "  -1.20805129e-01 -1.86520600e-01 -1.49726760e-01  1.95260824e-01\n",
      "  -2.19702450e-01  7.70482845e-02  1.62760917e-02 -5.21992731e-02\n",
      "  -1.52100826e-02 -6.91473397e-04 -2.29154966e-02 -1.57070508e-02\n",
      "  -1.62885885e-01  1.61206419e-01  1.21534039e-01  3.89275198e-02\n",
      "   6.83024031e-02  1.05882980e-01 -5.30020919e-02  2.23437888e-01\n",
      "  -2.91849489e-02  3.92971569e-03 -1.46081047e-01 -1.85185639e-01\n",
      "   6.21535382e-02 -2.86732905e-02  2.63744567e-02  9.21577453e-02\n",
      "  -5.00138482e-02  1.71312608e-01  5.35277490e-03  5.57738984e-02\n",
      "   3.06362205e-02 -1.69653625e-02  1.21544658e-02 -1.95036515e-01\n",
      "   3.97908514e-02  9.60676765e-02  1.05938603e-02 -9.83467433e-02\n",
      "   5.03288415e-02 -3.43258899e-02  3.01547459e-02  2.80713517e-02\n",
      "   1.23577456e-02 -1.22308838e-01 -2.05400650e-01 -5.79277131e-03\n",
      "  -1.61583354e-01 -5.00244758e-02 -7.69456102e-02  8.25091133e-02\n",
      "   9.34102017e-02  3.27575375e-02  1.49907165e-01 -1.46910988e-01\n",
      "   1.39421600e-01 -1.33558711e-01  1.54514116e-01  2.36541929e-02\n",
      "  -3.84906351e-02 -1.58128190e-01  1.23166115e-01  2.91616622e-01\n",
      "  -5.85738805e-02 -1.44877519e-01 -1.34745519e-01 -3.51602802e-02\n",
      "   1.59859750e-01  3.52593598e-02  3.29369340e-02  2.68487643e-01\n",
      "   6.68661005e-02  2.04581449e-01 -9.67128409e-03  5.61416736e-03\n",
      "   1.08528475e-01  2.36169103e-03 -1.75983770e-01  1.61839096e-01\n",
      "   2.70705800e-01 -1.87510506e-01 -1.45305750e-01 -3.07444947e-01\n",
      "  -4.23104906e-02  2.51696019e-02  9.49642149e-02  3.88020816e-02\n",
      "  -6.53608407e-02 -1.83082587e-01  3.19637910e-01  3.55095210e-02\n",
      "  -2.98335061e-03 -6.87524933e-02 -2.54608539e-02 -1.82377986e-01\n",
      "   9.81022606e-02  8.88761372e-02  2.31733108e-01  1.96871714e-02\n",
      "   1.78878008e-02 -6.67160586e-02 -1.19284436e-01 -1.51987084e-01\n",
      "   4.09695359e-01  1.36375064e-01  6.49867313e-02  3.71794115e-01\n",
      "  -8.06571580e-02  2.72523278e-01  7.40442101e-02 -1.72192403e-01\n",
      "   2.98716396e-02 -7.91490058e-02 -5.72255215e-02 -3.03862484e-01\n",
      "   8.27866700e-02 -8.25448842e-02  3.49670220e-02  2.00777249e-01\n",
      "   3.11078972e-01 -9.05839083e-02 -2.74465815e-01 -4.70348659e-02\n",
      "   1.89139890e-01 -2.71805638e-02  1.32445187e-01 -3.94083911e-02\n",
      "  -1.02605578e-01  2.34338401e-02  4.48112138e-03 -4.32314271e-02\n",
      "  -2.55449408e-01 -5.76743592e-02 -8.63181057e-02 -1.20238063e-02\n",
      "  -1.69468025e-01 -2.05293110e-02 -3.78533018e-02 -3.83634819e-02\n",
      "   1.94675032e-02  2.22986790e-02 -5.13732934e-02  7.19873167e-02\n",
      "  -8.32837893e-02  9.70448169e-02 -5.97292724e-02  2.54209380e-02\n",
      "   2.04639843e-01 -3.40164440e-02  1.10954649e-01 -2.45833380e-02\n",
      "   2.42550721e-02 -9.88924150e-02 -1.28201132e-02  2.18983682e-01\n",
      "  -4.39125623e-01 -2.38226843e-01  2.82312402e-01  1.65754272e-01\n",
      "  -4.62635542e-02  3.94371049e-01 -5.24518903e-02 -2.19569218e-02\n",
      "   1.47764011e-01  1.06707462e-01  2.35981772e-01 -5.58236753e-02\n",
      "   7.97632584e-02  5.42563540e-02 -1.16522662e-01  4.26898866e-01\n",
      "   9.92835336e-02 -2.54705875e-01  1.75182191e-01 -7.65519703e-02\n",
      "   1.41210417e-01 -6.22634391e-03  2.08176231e-01  3.52046060e-01\n",
      "  -1.14821785e-02 -4.20572233e-02  2.70037993e-01 -5.26353235e-02\n",
      "   2.80760943e-02  1.63751245e-02 -2.16325933e-01  2.15190902e-01\n",
      "   1.00928568e-01  3.21231944e-01 -1.61174167e-01 -1.75216437e-01\n",
      "   4.21435231e-02 -9.87850102e-02  1.50681050e-02  1.73185862e-01\n",
      "   2.73660329e-01  3.95434674e-03 -9.29119675e-02  1.16961106e-01\n",
      "  -3.19451275e-01 -1.45556956e-01 -3.80627859e-01  5.07346256e-02\n",
      "  -4.92306145e-01  1.68296855e-01  1.37106304e-01 -5.28220391e-01\n",
      "  -2.80337702e-01 -8.88619332e-02  1.92209541e-01  8.01160903e-02\n",
      "   2.21156471e-01 -2.01342228e-01 -3.16680245e-01  4.18544480e-01\n",
      "   6.95254884e-02  3.94662743e-01 -3.22666942e-01 -1.11156759e-01\n",
      "  -1.89710890e-01  9.69431861e-03  2.05479304e-01  2.46080163e-01\n",
      "  -1.40990604e-01 -2.61478381e-01  2.11538277e-01 -2.39644199e-01\n",
      "   1.09140327e-01  9.10019239e-02 -2.36674883e-01 -6.52861678e-03\n",
      "  -1.59429610e-01  8.10661941e-02 -4.31751438e-02 -4.40227020e-01\n",
      "   6.07024360e-02  1.73043763e-01  2.05598750e-02 -1.13759197e-01\n",
      "  -4.81832761e-02 -6.61433501e-04 -7.07002055e-03  4.09027599e-02\n",
      "  -2.29331563e-02 -2.98005762e-02  1.61316681e-01 -1.67805634e-01\n",
      "  -1.82013697e-01  1.11784760e-01 -4.81981246e-02 -2.50805841e-01\n",
      "   6.22547471e-02 -7.65266918e-02 -1.01073437e-03  2.99056901e-02\n",
      "  -2.88723607e-01 -2.34659764e-01 -3.49855529e-02  9.98195627e-03\n",
      "   2.11278756e-02  1.85638789e-01 -4.98545862e-02 -2.70796470e-03\n",
      "   1.26861109e-01  6.69691518e-02 -6.26846403e-02 -1.41513590e-01\n",
      "  -4.21650063e-02 -4.68360361e-02 -1.00543829e-01  3.25961541e-02\n",
      "  -1.37082571e-01 -1.43689670e-02 -5.22662199e-02  1.33636899e-01\n",
      "  -1.75655451e-01  1.38713636e-01  2.71594159e-01  6.35782186e-02\n",
      "  -2.64897045e-02 -2.68035354e-02 -6.53472524e-02 -7.56288252e-03\n",
      "  -2.50087434e-02 -9.10056367e-02  1.17266493e-01  1.97117200e-01\n",
      "   3.07109944e-02 -5.50758557e-02  5.91274522e-02 -1.49259614e-01\n",
      "   2.23810642e-01 -8.72235908e-02 -2.05583386e-03  1.91431664e-02\n",
      "  -2.68291992e-02  6.58536806e-02 -5.06849358e-02 -8.11078785e-02\n",
      "  -1.76519848e-01  1.47869791e-01  1.33740131e-01 -3.52785577e-02\n",
      "  -2.13540642e-01  8.00095326e-03  1.63481003e-01  5.14232614e-02\n",
      "  -1.73614643e-01  2.86179864e-01  8.75732504e-02 -3.75157149e-02\n",
      "   1.39607320e-02  1.48303451e-01  2.20851597e-03 -3.11431515e-02\n",
      "   9.20002717e-02  1.67035752e-01 -1.21697227e-01  3.62652860e-01\n",
      "  -1.67661415e-01  6.70537835e-02 -6.26168951e-02 -6.16369141e-02\n",
      "  -4.60326801e-02  1.05725018e-02  4.36950599e-02 -9.17172876e-02\n",
      "  -1.28884888e-01  9.65627917e-02 -4.19791223e-02  1.26676863e-01\n",
      "  -1.23849471e-01 -1.88417114e-01 -3.69069389e-02  6.52663168e-02\n",
      "  -1.26051009e-01 -3.95549731e-03  2.45496132e-02  4.27909001e-02\n",
      "   1.35630341e-01  6.77627793e-02  1.79934580e-01 -1.91028799e-01\n",
      "   7.76342642e-02 -3.20280369e-01  2.67743253e-01  7.46090082e-02\n",
      "  -8.75741036e-02 -2.86370553e-02 -6.12106287e-03  3.67201186e-02\n",
      "   8.56398798e-02 -1.14745974e-01  1.09860768e-01 -1.32603879e-01\n",
      "  -9.44399706e-02 -8.03693777e-02  1.12087337e-01 -5.62403465e-03\n",
      "  -1.19432188e-02 -3.69704675e-02 -2.94155023e-02  3.43456569e-02\n",
      "  -1.37726418e-01  7.54642221e-02  7.29439680e-02 -1.65409590e-01\n",
      "   2.83095099e-02  6.07573717e-02 -5.38780547e-02  1.31161933e-01\n",
      "  -1.61133307e-02 -4.83712730e-02 -7.77650511e-02  4.87270144e-02\n",
      "  -1.46593402e-01  7.92733391e-02  7.00896699e-02 -2.24959223e-02\n",
      "  -6.32437675e-02  3.18614104e-03 -1.18449901e-01  1.14059060e-01\n",
      "  -1.26243618e-01 -1.53444010e-01 -1.39763573e-01  9.29845966e-02\n",
      "  -5.59420509e-02 -9.53293978e-03 -2.37644261e-03 -3.57228421e-02\n",
      "  -3.82711639e-02 -1.22257255e-01 -3.29380626e-02 -2.84938898e-02\n",
      "  -3.88807747e-01  1.02998470e-01 -5.78386343e-03 -1.41444505e-01\n",
      "  -2.29467772e-01 -1.53177126e-01 -2.99328771e-01  3.42291033e-03\n",
      "  -2.52621938e-01 -2.91380997e-01  7.13083675e-02  6.21425062e-02\n",
      "   1.11602606e-01 -2.88948194e-01 -2.09964440e-01  2.72968277e-01\n",
      "   2.12376823e-02  2.38367978e-01 -2.72829381e-03 -2.32500671e-01\n",
      "   2.00064794e-01  6.06741074e-02 -3.49302888e-02  8.33411625e-02\n",
      "   1.71972649e-01 -4.24381985e-02 -2.74150236e-01  2.47627407e-02\n",
      "   1.20190028e-01 -2.61420952e-01  9.89115506e-02 -9.40126165e-02\n",
      "  -5.18373444e-02 -3.07176267e-01  7.19381005e-03 -2.86758794e-01\n",
      "  -1.14267644e-02 -1.11202637e-01 -6.31310002e-02 -1.87779827e-01\n",
      "   3.37326121e-02 -2.58932120e-01  1.43802772e-01 -3.93114298e-02\n",
      "  -3.27199864e-02  1.15433521e-01 -1.62936442e-01  1.78441740e-02\n",
      "   8.06530460e-02 -7.33585063e-02 -8.93804200e-02 -2.49015787e-01\n",
      "   8.94921718e-02 -3.92970734e-02 -1.12085162e-02  1.30453994e-01\n",
      "  -8.14903937e-02  3.12455173e-02 -2.09808137e-02  1.69507702e-01\n",
      "  -8.01690679e-02 -2.31932169e-01  7.46085039e-02  4.94386164e-02\n",
      "  -6.34395751e-02 -8.78823886e-02 -4.43176137e-02 -6.49473364e-02\n",
      "  -1.01111474e-01  8.08627928e-03 -2.62887739e-01 -2.14336225e-01\n",
      "   6.83713501e-02  2.15748817e-02  5.79244906e-02 -2.85397629e-02\n",
      "  -6.70630210e-02  9.93157933e-02 -4.10035759e-02  2.77611822e-02\n",
      "  -2.22296106e-02 -1.67936020e-01 -3.11889628e-02 -1.04351975e-01\n",
      "   4.74859849e-02  4.22778780e-02 -1.34739761e-01 -3.73811436e-02]]\n",
      "Optimized intercept -0.6758351531842354\n",
      "Training Accuracy 0.927981162253421\n",
      "Test Accuracy 0.9360767079504595\n",
      "used time: 20.179226398468018\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start=time.time()\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "w,b = weightInitialzation(n_features)\n",
    "\n",
    "coeff,gradient,costs = model_training(w,b,X_train,Y_train,learning_rate=0.1,no_iterations=1000)\n",
    "w = coeff['w']\n",
    "b = coeff['b']\n",
    "\n",
    "print('Optimized weights', w)\n",
    "print('Optimized intercept',b)\n",
    "final_train_pred = sigmoid_activation(np.dot(w,X_train.T)+b)\n",
    "final_test_pred = sigmoid_activation(np.dot(w,X_test.T)+b)\n",
    "m_tr =  X_train.shape[0]\n",
    "m_ts =  X_test.shape[0]\n",
    "y_tr_pred = predict(final_train_pred, m_tr)\n",
    "print('Training Accuracy',accuracy_score(y_tr_pred.T, Y_train))\n",
    "#\n",
    "y_ts_pred = predict(final_test_pred, m_ts)\n",
    "print('Test Accuracy',accuracy_score(y_ts_pred.T, Y_test))\n",
    "\n",
    "print('used time: {}'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:50:34.999426Z",
     "start_time": "2019-06-15T09:50:34.994960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10570265, 0.97017004, 0.99564724, ..., 0.69903733, 0.09619968,\n",
       "        0.94804838]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:50:35.005406Z",
     "start_time": "2019-06-15T09:50:35.000416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.10570265, 0.97017004, 0.99564724, ..., 0.69903733, 0.09619968,\n",
       "        0.94804838])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(final_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:50:35.122433Z",
     "start_time": "2019-06-15T09:50:35.006400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title('Cost reduction over time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:50:41.721668Z",
     "start_time": "2019-06-15T09:50:35.123920Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from sk-learn: 0.9368757491010787\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(max_iter=10)\n",
    "clf.fit(X_train, Y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print ('Accuracy from sk-learn: {0}'.format(clf.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测测试文本是否为抄袭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:53:53.588170Z",
     "start_time": "2019-06-15T09:53:53.582747Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "testText = \"根据本社记者报道，法国总统在法国巴黎的凡尔赛宫出席新闻发布会。\"\n",
    "testText = testText[::-1]\n",
    "\n",
    "tokens_list = cut(testText).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:53:53.730564Z",
     "start_time": "2019-06-15T09:53:53.726595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'。会布发闻新席出宫赛尔凡的黎巴国法在统总国法，道报者记社本据根'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:53:53.889633Z",
     "start_time": "2019-06-15T09:53:53.884700Z"
    }
   },
   "outputs": [],
   "source": [
    "def checkXinHua(final_pred):\n",
    "    print(\"There is about {} % is plagiarism\".format(final_pred[0]))\n",
    "    if final_pred[0]>0.5:\n",
    "        print(\"Plagiarism!!!!!!!\")\n",
    "    else:\n",
    "        print(\"Ok\")\n",
    "\n",
    "\n",
    "testVector = data.model.infer_vector(tokens_list)\n",
    "final = sigmoid_activation(np.dot(w,testVector.T)+b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:53:54.054288Z",
     "start_time": "2019-06-15T09:53:54.049300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T09:53:54.233414Z",
     "start_time": "2019-06-15T09:53:54.230464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is about 0.3316453149433756 % is plagiarism\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "checkXinHua(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
