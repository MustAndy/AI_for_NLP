{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:53:27.490909Z",
     "start_time": "2019-08-09T02:53:25.914278Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "\n",
    "data_files = ['D:/senior/aiCourse/dataSource/comment_classification/output/train.json']\n",
    "vocab_file = 'D:/senior/aiCourse/dataSource/comment_classification/output/vocab.txt'\n",
    "label_file = 'D:/senior/aiCourse/dataSource/comment_classification/labels.txt'\n",
    "enb_file = 'D:/senior/aiCourse/dataSource/comment_classification/embedding/embedding.txt'\n",
    "batch_size = 128\n",
    "reverse = False\n",
    "split_word = True\n",
    "max_len = 400\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:53:27.497594Z",
     "start_time": "2019-08-09T02:53:27.490909Z"
    }
   },
   "outputs": [],
   "source": [
    "data_files=['../../../dataSource/comment_classification/output/train.json']\n",
    "vocab_file = '../../../dataSource/comment_classification/output/vocab.txt'\n",
    "label_file = '../../../dataSource/comment_classification/labels.txt'\n",
    "enb_file = '../../../dataSource/comment_classification/output/embedding.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:53:37.745345Z",
     "start_time": "2019-08-09T02:53:27.499587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# vocab size:  50000\n",
      "# vocab size:  20\n",
      "# Start to preprocessing data...\n",
      "# load data from ../../../dataSource/comment_classification/output/train.json ...\n",
      "# Got 105000 data items with 820 batches\n"
     ]
    }
   ],
   "source": [
    "dataset1 = DataSet(  data_files,  vocab_file,   label_file,   batch_size, reverse=  reverse, split_word=  split_word, max_len=  max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:53:37.825131Z",
     "start_time": "2019-08-09T02:53:37.747304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402\n"
     ]
    }
   ],
   "source": [
    "for i,(source, lengths, targets, _) in enumerate(dataset1.get_next()):\n",
    "    print(len(source[9]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:53:37.831079Z",
     "start_time": "2019-08-09T02:53:37.826095Z"
    }
   },
   "outputs": [],
   "source": [
    "def dig_lists(l):\n",
    "    output = []\n",
    "    for e in l:\n",
    "        if isinstance(e, list):\n",
    "            output += dig_lists(e)\n",
    "        else:\n",
    "            output.append(e)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:53:37.839850Z",
     "start_time": "2019-08-09T02:53:37.831868Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_sequences(comment_to_id,maxlen,padding,truncating):\n",
    "    features = np.zeros((len(comment_to_id), maxlen), dtype=int)\n",
    "    for i,comment in enumerate(comment_to_id):\n",
    "        if len(comment) <= maxlen and padding == 'pre':\n",
    "            features[i, -len(comment):] = np.array(comment)[:maxlen]\n",
    "        if len(comment) <= maxlen and padding == 'post':\n",
    "            features[i, :len(comment)] = np.array(comment)[:maxlen]\n",
    "        if len(comment) > maxlen and truncating == 'post':\n",
    "            features[i, :] = np.array(comment)[:maxlen]\n",
    "        if len(comment) > maxlen and truncating == 'pre':\n",
    "            features[i, :] = np.array(comment)[len(comment)-maxlen:]           \n",
    "    return features\n",
    "\n",
    "def split_dataset(pad_comments,labels,split_frac):\n",
    "    split_index = int(len(pad_comments)*split_frac)\n",
    "    data_list = list(zip(pad_comments, labels))\n",
    "    random.shuffle(data_list)\n",
    "    pad_comments, labels = zip(*data_list)\n",
    "    x_train, x_test = pad_comments[:split_index], pad_comments[split_index:]\n",
    "    y_train, y_test = labels[:split_index], labels[split_index:]\n",
    "    return x_train,y_train,x_test,y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:53:38.707902Z",
     "start_time": "2019-08-09T02:53:37.840848Z"
    }
   },
   "outputs": [],
   "source": [
    "comment_to_id = [x[0] for x in dataset1._raw_data]\n",
    "pad_comments = pad_sequences(comment_to_id,maxlen=max_len,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:53:39.289954Z",
     "start_time": "2019-08-09T02:53:38.709530Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = [x[2].flatten().tolist() for x in dataset1._raw_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:53:39.311896Z",
     "start_time": "2019-08-09T02:53:39.291948Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "x_train,y_train,x_test,y_test = split_dataset(pad_comments[:10000],labels,0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T03:44:21.985432Z",
     "start_time": "2019-08-09T03:44:21.968999Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers as initializers, regularizers, constraints\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import concatenate,GlobalMaxPooling1D,GlobalAveragePooling1D,SpatialDropout1D,Embedding, Input, Dense, LSTM, GRU, Bidirectional, TimeDistributed\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import keras.layers as layers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Embedding,LSTM,Bidirectional,Layer\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:53:39.718216Z",
     "start_time": "2019-08-09T02:53:39.668268Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:55:40.646970Z",
     "start_time": "2019-08-09T02:55:40.643947Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_size = 256\n",
    "inp = Input(shape=(400, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:55:41.140709Z",
     "start_time": "2019-08-09T02:55:41.111765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_3/embedding_lookup/Identity:0\", shape=(?, 400, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = Embedding(input_dim=len(dataset1.w2i), output_dim=embed_size,)(inp)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:55:42.679390Z",
     "start_time": "2019-08-09T02:55:42.656452Z"
    }
   },
   "outputs": [],
   "source": [
    "x = SpatialDropout1D(0.2)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:55:44.119681Z",
     "start_time": "2019-08-09T02:55:43.891936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"bidirectional_7/concat:0\", shape=(?, ?, 200), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x1 = Bidirectional(GRU(100, return_sequences=True))(x)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:55:45.396536Z",
     "start_time": "2019-08-09T02:55:44.925395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"bidirectional_8/concat:0\", shape=(?, ?, 200), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x2 = Bidirectional(GRU(100, return_sequences=True))(x1)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:55:46.293407Z",
     "start_time": "2019-08-09T02:55:46.074570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"bidirectional_9/concat:0\", shape=(?, ?, 200), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x3 = Bidirectional(GRU(100, return_sequences=True))(x2)\n",
    "print(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:56:16.450750Z",
     "start_time": "2019-08-09T02:56:16.433796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, ?, 600) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenate([x1, x2,x3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:56:36.598931Z",
     "start_time": "2019-08-09T02:56:36.587940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_2/concat:0' shape=(?, 400) dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pool = GlobalAveragePooling1D()(x3)\n",
    "max_pool = GlobalMaxPooling1D()(x3)\n",
    "concatenate([avg_pool, max_pool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outp = Dense(80, activation=\"relu\")(x3)\n",
    "model = Model(inputs=x3, outputs=outp)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T03:46:42.926721Z",
     "start_time": "2019-08-09T03:46:42.904639Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(x, axis=1):\n",
    "    \"\"\"Softmax activation function.\"\"\"\n",
    "    ndim = K.ndim(x)\n",
    "    if ndim == 2:\n",
    "        return K.softmax(x)\n",
    "    elif ndim > 2:\n",
    "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "        s = K.sum(e, axis=axis, keepdims=True)\n",
    "        return e / s\n",
    "    else:\n",
    "        raise ValueError('Cannot apply softmax to a tensor that is 1D')\n",
    "        \n",
    "        \n",
    "densor1 = Dense(32, activation = \"tanh\")\n",
    "densor2 = Dense(1, activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "dotor = Dot(axes = 1)\n",
    "def one_step_attention(a):\n",
    "    e = densor1(a)\n",
    "    energies = densor2(e)\n",
    "    alphas = activator(energies)\n",
    "    context = dotor([alphas,a])\n",
    "    return context\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    inp = Input(shape=(400,))\n",
    "    x = Embedding(50000, 256)(inp)\n",
    "    x = Bidirectional(CuDNNGRU(64, return_sequences= True))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    context = one_step_attention(x)\n",
    "    context = Flatten()(context)\n",
    "    merged = Dropout(0.25)(context)\n",
    "    merged = BatchNormalization()(merged)\n",
    "    preds = Dense(80, activation='relu')(merged)\n",
    "    model = Model(inputs = [inp], outputs= preds)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:53:53.184951Z",
     "start_time": "2019-08-09T02:53:53.177964Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    embed_size = 256\n",
    "    inp = Input(shape=(400, ))\n",
    "    x = Embedding(input_dim=len(dataset1.w2i), output_dim=embed_size,)(inp)\n",
    "    print(x)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x1 = Bidirectional(GRU(100, return_sequences=True))(x)\n",
    "    x2 = Bidirectional(GRU(100, return_sequences=True))(x1)\n",
    "    x3 = Bidirectional(GRU(100, return_sequences=True))(x2)\n",
    "        \n",
    "    outp = Dense(80, activation=\"relu\")(x3)\n",
    "    model = Model(inputs=x3, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "    \n",
    "    avg_pool = GlobalAveragePooling1D()(x3)\n",
    "    max_pool = GlobalMaxPooling1D()(x3)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    outp = Dense(80, activation=\"relu\")(conc)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T03:46:46.268761Z",
     "start_time": "2019-08-09T03:46:45.136021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 400, 256)     12800000    input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 400, 128)     123648      embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 400, 128)     0           bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 400, 32)      4128        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 400, 1)       33          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 400, 1)       0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 128)       0           attention_weights[0][0]          \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128)          512         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 80)           10320       batch_normalization_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 12,938,641\n",
      "Trainable params: 12,938,385\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T03:46:57.150085Z",
     "start_time": "2019-08-09T03:46:53.027990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 400, 256)     12800000    input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 400, 128)     123648      embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 400, 128)     0           bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 400, 32)      4128        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 400, 1)       33          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 400, 1)       0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 128)       0           attention_weights[0][0]          \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128)          512         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 80)           10320       batch_normalization_1[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 12,938,641\n",
      "Trainable params: 12,938,385\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[node bidirectional_10/CudnnRNN (defined at e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py:922)  = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"gru\", seed=87654321, seed2=0](bidirectional_10/transpose, bidirectional_10/ExpandDims_1, bidirectional_10/Const, bidirectional_10/concat)]]\n\nCaused by op 'bidirectional_10/CudnnRNN', defined at:\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-32-154615619aa0>\", line 1, in <module>\n    model = get_model()\n  File \"<ipython-input-31-9db78388efcb>\", line 21, in get_model\n    x = Bidirectional(CuDNNGRU(64, return_sequences= True))(x)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\keras\\layers\\wrappers.py\", line 427, in __call__\n    return super(Bidirectional, self).__call__(inputs, **kwargs)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\keras\\layers\\wrappers.py\", line 522, in call\n    y = self.forward_layer.call(inputs, **kwargs)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py\", line 90, in call\n    output, states = self._process_batch(inputs, initial_state)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py\", line 297, in _process_batch\n    is_training=True)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 1621, in __call__\n    seed=self._seed)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 1010, in _cudnn_rnn_no_input_c\n    direction, dropout, seed, name)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 922, in _cudnn_rnn\n    outputs, output_h, output_c, _ = gen_cudnn_rnn_ops.cudnn_rnn(**args)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\python\\ops\\gen_cudnn_rnn_ops.py\", line 144, in cudnn_rnn\n    is_training=is_training, name=name)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[node bidirectional_10/CudnnRNN (defined at e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py:922)  = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"gru\", seed=87654321, seed2=0](bidirectional_10/transpose, bidirectional_10/ExpandDims_1, bidirectional_10/Const, bidirectional_10/concat)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32me:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1316\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1317\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[1;32me:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1351\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1352\u001b[1;33m       \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[{{node bidirectional_10/CudnnRNN}} = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"gru\", seed=87654321, seed2=0](bidirectional_10/transpose, bidirectional_10/ExpandDims_1, bidirectional_10/Const, bidirectional_10/concat)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-80b9860b3267>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32me:\\anaconda\\envs\\aicourse\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32me:\\anaconda\\envs\\aicourse\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\aicourse\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2696\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2697\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_make_callable_from_options'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2698\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2699\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\aicourse\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    197\u001b[0m                 \u001b[1;31m# not already marked as initialized.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 is_initialized = session.run(\n\u001b[1;32m--> 199\u001b[1;33m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[node bidirectional_10/CudnnRNN (defined at e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py:922)  = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"gru\", seed=87654321, seed2=0](bidirectional_10/transpose, bidirectional_10/ExpandDims_1, bidirectional_10/Const, bidirectional_10/concat)]]\n\nCaused by op 'bidirectional_10/CudnnRNN', defined at:\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tornado\\gen.py\", line 781, in inner\n    self.run()\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tornado\\gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-32-154615619aa0>\", line 1, in <module>\n    model = get_model()\n  File \"<ipython-input-31-9db78388efcb>\", line 21, in get_model\n    x = Bidirectional(CuDNNGRU(64, return_sequences= True))(x)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\keras\\layers\\wrappers.py\", line 427, in __call__\n    return super(Bidirectional, self).__call__(inputs, **kwargs)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\keras\\layers\\wrappers.py\", line 522, in call\n    y = self.forward_layer.call(inputs, **kwargs)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py\", line 90, in call\n    output, states = self._process_batch(inputs, initial_state)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py\", line 297, in _process_batch\n    is_training=True)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 1621, in __call__\n    seed=self._seed)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 1010, in _cudnn_rnn_no_input_c\n    direction, dropout, seed, name)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 922, in _cudnn_rnn\n    outputs, output_h, output_c, _ = gen_cudnn_rnn_ops.cudnn_rnn(**args)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\python\\ops\\gen_cudnn_rnn_ops.py\", line 144, in cudnn_rnn\n    is_training=is_training, name=name)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CudnnRNN' with these attrs.  Registered devices: [CPU], Registered kernels:\n  <no registered kernels>\n\n\t [[node bidirectional_10/CudnnRNN (defined at e:\\anaconda\\envs\\aicourse\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py:922)  = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"gru\", seed=87654321, seed2=0](bidirectional_10/transpose, bidirectional_10/ExpandDims_1, bidirectional_10/Const, bidirectional_10/concat)]]\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "history = model.fit(x_train, y_train,epochs=2,verbose=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:26:45.964222Z",
     "start_time": "2019-08-09T02:26:45.936293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27148858, 0.        , 0.03656801, 0.49509174, 0.16101427,\n",
       "        0.        , 0.        , 0.4964216 , 0.2141101 , 0.01124754,\n",
       "        0.        , 0.        , 0.04661782, 0.04072843, 0.19887982,\n",
       "        0.43112528, 0.37832567, 0.10584863, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.08206163, 0.39976266, 0.        ,\n",
       "        0.        , 0.        , 0.48179057, 0.15471175, 0.1760441 ,\n",
       "        0.23459688, 0.47964907, 0.24099392, 0.        , 0.04933136,\n",
       "        0.4643405 , 0.18672746, 0.22675116, 0.01986222, 0.5704697 ,\n",
       "        0.29397368, 0.3688913 , 0.        , 0.7803701 , 0.3242618 ,\n",
       "        0.0779756 , 0.03781231, 0.4317289 , 0.23610915, 0.14585766,\n",
       "        0.06815854, 0.47883025, 0.2631844 , 0.07373718, 0.04461501,\n",
       "        0.4500302 , 0.40371394, 0.        , 0.        , 0.4848981 ,\n",
       "        0.4600464 , 0.33543804, 0.04280333, 0.02706825, 0.23082788,\n",
       "        0.06336311, 0.        , 0.4076091 , 0.2201471 , 0.01970156,\n",
       "        0.03127155, 0.6290768 , 0.        , 0.3157961 , 0.14496681,\n",
       "        0.        , 0.263781  , 0.0493007 , 0.        , 0.34170583]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T02:24:42.564702Z",
     "start_time": "2019-08-09T02:24:42.559710Z"
    }
   },
   "source": [
    "def get_model():\n",
    "    embed_size = 256\n",
    "    model = Sequential()   \n",
    "    \n",
    "    model.add( Embedding(50000, embed_size,input_length=400))\n",
    "    \n",
    "    \n",
    "    model.add(Bidirectional(GRU(100, return_sequences=False)))\n",
    "    #model.add(SpatialDropout1D(0.2))\n",
    "              \n",
    "    #model.add(Bidirectional(GRU(100, return_sequences=True)))\n",
    "    \n",
    "    #model.add(GlobalAveragePooling1D())\n",
    "    model.add(Dense(80, activation=\"relu\"))\n",
    "    \n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "preds = model.predict(x_train)\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "print(accuracy(preds,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_2_labels(answer):\n",
    "    labels_input = []\n",
    "    for item in answer:\n",
    "        answer_temp = []\n",
    "        for i in range(0,80,4):\n",
    "            answer_temp.append(np.argmax(item[i:i+4]))\n",
    "        labels_input.append(answer_temp)\n",
    "    return labels_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_2_labels(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coun=0\n",
    "all1=0\n",
    "for line in convert_2_labels(y_train):\n",
    "    for item in line:\n",
    "        if item == 3:\n",
    "            coun+=1\n",
    "        all1+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
